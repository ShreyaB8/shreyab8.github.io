{"basics":{"name":"Shreyashri Biswas","label":"Electrical and Computer Engineer","image":"","email":"sbiswas2@andrew.cmu.edu","phone":"+1(412) 909-9766","url":"https://simplyshreya.in/","summary":"Master of Science in Electrical and Computer Engineering from Carnegie Mellon University with a strong background in machine learning, high-performance computing, and computer architectures. Passionate about developing efficient AI/ML systems and optimizing computer performance.","location":{"address":"","postalCode":"","city":"Pittsburgh","countryCode":"US","region":"Pennsylvania"},"profiles":[{"network":"LinkedIn","username":"shreyab8","url":"https://linkedin.com/in/shreyab8/"}]},"work":[{"name":"AMD","position":"Applied Machine Learning System Architecture Engineering Intern","url":"","startDate":"2023-05-01","endDate":"2023-08-01","summary":"Explored optimal model size and inference latency on AMDâ€™s AI accelerator. Utilized Quantization techniques to achieve significant model size reduction and latency improvements.","highlights":[]},{"name":"Bosch","position":"Research Intern","url":"","startDate":"2021-11-01","endDate":"2022-02-01","summary":"Designed an end-to-end system to predict accident-prone junction areas on Indian roads with 88% accuracy.","highlights":[]},{"name":"Konwert India Motors","position":"AI/ML and IoT Developer","url":"","startDate":"2021-03-01","endDate":"2021-07-01","summary":"Developed a custom LSTM model for predicting the health of electric vehicles, achieving significant improvements over previous models.","highlights":[]}],"education":[{"institution":"Carnegie Mellon University","location":"Pittsburgh, USA","url":"","area":"Electrical and Computer Engineering","studyType":"MSc","startDate":"2022","endDate":"2023","score":"3.4/4","courses":["Intro to Deep Learning","Modern Computer Architecture","On Device ML","How to Write Fast Code: GPU Parallel Programming","Optimization","Visual Learning and Recognition","Large Language Models","Deep Learning Systems"]},{"institution":"SRM Institute of Science and Technology","location":"Chennai, India","url":"","area":"Electronics and Communication Engineering","studyType":"BTech","startDate":"2018","endDate":"2022","score":"9.25/10","courses":[]}],"skills":[{"name":"Programming","level":"Advanced","keywords":["C++","Python","PyTorch","Tensorflow","Jax"]},{"name":"High-Performance Computing and Machine Learning Systems","level":"Advanced","keywords":["Edge AI","Deep Learning","Machine Learning","SIMD","CUDA","OpenMP","OpenGL","VitisAI","ARMNN","TVM"]},{"name":"Computer Architectures","level":"Advanced","keywords":["CPU (x86, ARM)","GPU (NVIDIA)","Qualcomm DSP","CGRA (AMD AI Engine)"]}],"languages":[{"language":"English","fluency":"Fluent"}],"research":[{"name":"Research Assistant in Catalyst Lab","summary":"Accelerating LLM inference through the speculative decoding process. Implementing a teacher-student model to propose candidate sequences for the large model to verify. Achieving 2X-3X speedup without altering outputs, by parallelizing token computation.","highlights":["Paper submitted on ARxive"]},{"name":"Research Assistant in Catalyst Lab","summary":"Engineered a compiler system for deep learning graph optimization and op-fusion targeting mobile backends with heterogeneous computer architecture. Implemented a kernel mapping strategy leveraging TVM and TASO, enhancing performance","highlights":["Paper submitted on ASPLOS"]},{"name":"Research Assistant in Speed Lab","summary":"Designed high performant SIMD kernels for Qualcomm heterogeneous multicore CPU for Computer Vision blurring algorithms. Leveraged performance engineering techniques such as instruction pipelining, tiling for efficient data movement, and SIMD ARM Neon. Intrinsics to maximize hardware utilization achieving 17% speedup benchmarked against OpenCV C++ kernelse"}],"projects":[{"name":"Stress testing and Improved performance of Asymmetric cores of SoC ","highlights":["Stress tested the SoC using benchmarks Dhrystone and Linpack. Achieved 6% misprediction rate, 10% L1 miss rate and bottlenecked L2 cache by 45% miss rate","Wrote programs with low instruction-level parallelism, multithreaded program with high ILP and a hybrid (both low and high ILP ) program for maximizing the performance-power trade offs of asymmetric cores."],"startDate":"2023-01-01","endDate":"Present","url":""},{"name":"Swin-Vision Transformer for edge device","summary":"Optimized vision transformers for edge devices, achieving significant memory and latency savings.","highlights":[],"startDate":"","endDate":"","url":""}]}